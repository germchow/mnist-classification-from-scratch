{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_93nsossprz",
        "outputId": "08e848b9-b3ad-40f0-eca0-d44b1e28d965"
      },
      "source": [
        "%pylab inline\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rm67cMnGwmA"
      },
      "source": [
        "# load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# normalize data between 0 and 1\n",
        "# x_train = (x_train/255).astype(np.float64)\n",
        "# x_test = (x_test/255).astype(np.float64)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYZ6Nl2A665H"
      },
      "source": [
        "def init_layer(m,n):\n",
        "  # random weights between 1 and -1\n",
        "  return np.random.uniform(-.1, .1, (m, n)).astype(np.float64)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = init_layer(128, 28*28)\n",
        "l2 = init_layer(10, 128)"
      ],
      "metadata": {
        "id": "LSfxmxgRJoeI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2QK0RpTe5EP"
      },
      "source": [
        "# relu activation \n",
        "def relu(x):\n",
        "  return np.maximum(x, 0)\n",
        "\n",
        "# softmax activation\n",
        "def softmax(x):\n",
        "  # num = np.exp(x)\n",
        "  # sum = np.exp(x).sum()\n",
        "  # print(\"num\", num, \"softmax sum\", sum)\n",
        "  # return num/sum\n",
        "  return np.exp(x - np.max(x)) / np.exp(x - np.max(x)).sum()\n",
        "\n",
        "# forward and backward pass (SGD)\n",
        "def single_pass(x, y):\n",
        "  # convert y to one-hot vector\n",
        "  y_oh = np.zeros((10, 1), dtype=np.float32)\n",
        "  y_oh[y] = 1\n",
        "\n",
        "  # flatten x and feed forward\n",
        "  x = x.reshape((28*28, 1))\n",
        "  x_l1 = l1.dot(x)\n",
        "  x_relu = relu(x_l1)\n",
        "  x_l2 = l2.dot(x_relu)\n",
        "  x_sm = softmax(x_l2)\n",
        "  y_pred = np.argmax(x_sm)\n",
        "\n",
        "  x_ce = np.sum(-y_oh * np.log(x_sm))\n",
        "\n",
        "  # d ce/l2_a | cross entropy\n",
        "  # d_ce = -y_oh / x_sm\n",
        "  \n",
        "  # d ce/l2_a * l2_a/l2_z | softmax \n",
        "  d_sm = x_sm - y_oh\n",
        "\n",
        "  # d ce/l2_a * l2_a/l2_z * l2_z/l2_w | l2 raw output\n",
        "  d_l2_w = np.matmul(x_relu, d_sm.T)\n",
        "\n",
        "  # d ce/l2_a * l2_a/l2_z * l2_z/l2_a\n",
        "  d_l2 = l2.T.dot(d_sm)\n",
        "\n",
        "  # d ce/l2_a * l2_a/l2_z * l2_z/l2_a * l2_a/l1_z | relu\n",
        "  d_relu = d_l2 * (x_l1 > 0).astype(np.float32)\n",
        "\n",
        "  # d ce/l2_a * l2_a/l2_z * l2_z/l2_a * l2_a/l1_z * l1_z/l1_w | l1 raw output\n",
        "  d_l1_w = np.matmul(x, d_relu.T)\n",
        "\n",
        "  return y_pred, d_l1_w, d_l2_w\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(learning_rate, iterations):\n",
        "  global l1, l2\n",
        "  train = np.random.randint(0, x_train.shape[0], size=iterations)\n",
        "\n",
        "  for i in range(iterations):\n",
        "    x = x_train[train[i]]\n",
        "    y = y_train[train[i]]\n",
        "    y_pred, d_l1, d_l2 = single_pass(x, y)\n",
        "    if i >= iterations - 10:\n",
        "      print(\"iteration \", i + 1, \" predicted: \", y_pred, \"actual:\", y)\n",
        "    \n",
        "    l1 = l1 - d_l1.T * learning_rate\n",
        "    l2 = l2 - d_l2.T * learning_rate"
      ],
      "metadata": {
        "id": "tL2K0y10er24"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_size):\n",
        "  test = np.random.randint(0, x_test.shape[0], size=test_size)\n",
        "  correct, total = 0,0\n",
        "  for i in range(50):\n",
        "    x = x_test[test[i]]\n",
        "    y = y_test[test[i]]\n",
        "    y_pred, d_l1, d_l2 = single_pass(x, y)\n",
        "    total += 1\n",
        "    if y_pred == y:\n",
        "      correct += 1\n",
        "    # print(\"iteration \", i + 1, \" predicted: \", y_pred, \"actual:\", y)\n",
        "\n",
        "  print(\"accuracy: \", correct/total)"
      ],
      "metadata": {
        "id": "0yy6lGySA0F3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(0.00005, 5000)\n",
        "test(y_train.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0pPNKfQDwZv",
        "outputId": "c5798246-96e5-402a-e2f9-cb99c7fcfc17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration  4991  predicted:  4 actual: 4\n",
            "iteration  4992  predicted:  5 actual: 5\n",
            "iteration  4993  predicted:  1 actual: 1\n",
            "iteration  4994  predicted:  7 actual: 7\n",
            "iteration  4995  predicted:  8 actual: 8\n",
            "iteration  4996  predicted:  6 actual: 6\n",
            "iteration  4997  predicted:  0 actual: 0\n",
            "iteration  4998  predicted:  6 actual: 6\n",
            "iteration  4999  predicted:  3 actual: 3\n",
            "iteration  5000  predicted:  9 actual: 7\n",
            "accuracy:  0.88\n"
          ]
        }
      ]
    }
  ]
}